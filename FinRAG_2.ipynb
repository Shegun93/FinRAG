{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6a95734-b590-4bee-b9f1-a45c96553550",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shegun93/anaconda3/envs/TTS/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/shegun93/anaconda3/envs/TTS/lib/python3.9/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/shegun93/anaconda3/envs/TTS/lib/python3.9/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# ====================\n",
    "# 1. Setup & Imports\n",
    "# ====================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import re\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "from datasets import load_dataset\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "nlp.add_pipe(\"sentencizer\")\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "embedding_model = SentenceTransformer(\"all-mpnet-base-v2\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0089cf12-1732-4f8e-b876-d0b54cf9f3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================\n",
    "# 2. Load & Preprocess Data\n",
    "# ====================\n",
    "def load_financial():\n",
    "    df = pd.read_csv(\"finaicial.csv\")\n",
    "    return df\n",
    "df = load_financial()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3dc7c019-35fa-47b8-964b-a1825ff4d41f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dd4bff516</td>\n",
       "      <td>containerboard , kraft papers and saturating k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dd4c55cc2</td>\n",
       "      <td>entergy mississippi , inc .\\nmanagement's fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dd4c5a718</td>\n",
       "      <td>we have a five year $ 1350 million revolving ,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dd4be0184</td>\n",
       "      <td>the agreements that govern the indebtedness in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dd4b93b5e</td>\n",
       "      <td>during 2005 , we amended our $ 1.0 billion uns...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         _id                                               text\n",
       "0  dd4bff516  containerboard , kraft papers and saturating k...\n",
       "1  dd4c55cc2  entergy mississippi , inc .\\nmanagement's fina...\n",
       "2  dd4c5a718  we have a five year $ 1350 million revolving ,...\n",
       "3  dd4be0184  the agreements that govern the indebtedness in...\n",
       "4  dd4b93b5e  during 2005 , we amended our $ 1.0 billion uns..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3e41a51-97a9-4cf4-a4fa-425447a77478",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv(\"finaicial.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d565bbd9-dfd7-4e07-a930-560290aca6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================\n",
    "# 3. Table Extraction\n",
    "# ====================\n",
    "def extract_table(text):\n",
    "    \"\"\"Extract markdown-style tables from text into DataFrames.\"\"\"\n",
    "    table_lines = [line for line in text.split(\"\\n\") if \"|\" in line]\n",
    "    if not table_lines:\n",
    "        return None\n",
    "    \n",
    "    # Split rows and pad with empty strings for consistent columns\n",
    "    table_data = [re.split(r\"\\s*\\|\\s*\", line.strip()) for line in table_lines]\n",
    "    max_cols = max(len(row) for row in table_data)\n",
    "    table_data = [row + [\"\"] * (max_cols - len(row)) for row in table_data]\n",
    "    \n",
    "    return pd.DataFrame(table_data[1:], columns=table_data[0])\n",
    "\n",
    "df[\"tables\"] = df[\"text\"].apply(extract_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43fe2418-6bd1-40fb-a58d-5b837637710a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>text</th>\n",
       "      <th>tables</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dd4bff516</td>\n",
       "      <td>containerboard , kraft papers and saturating k...</td>\n",
       "      <td>( in millions )  year ended september 30 , ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dd4c55cc2</td>\n",
       "      <td>entergy mississippi , inc .\\nmanagement's fina...</td>\n",
       "      <td>( in millions )\n",
       "0  ------...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dd4c5a718</td>\n",
       "      <td>we have a five year $ 1350 million revolving ,...</td>\n",
       "      <td>contractual oblig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dd4be0184</td>\n",
       "      <td>the agreements that govern the indebtedness in...</td>\n",
       "      <td>sites  corporate  bd life sciences  b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dd4b93b5e</td>\n",
       "      <td>during 2005 , we amended our $ 1.0 billion uns...</td>\n",
       "      <td>2006  $ 600883\n",
       "0  ----------  -------...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         _id                                               text  \\\n",
       "0  dd4bff516  containerboard , kraft papers and saturating k...   \n",
       "1  dd4c55cc2  entergy mississippi , inc .\\nmanagement's fina...   \n",
       "2  dd4c5a718  we have a five year $ 1350 million revolving ,...   \n",
       "3  dd4be0184  the agreements that govern the indebtedness in...   \n",
       "4  dd4b93b5e  during 2005 , we amended our $ 1.0 billion uns...   \n",
       "\n",
       "                                              tables  \n",
       "0     ( in millions )  year ended september 30 , ...  \n",
       "1                       ( in millions )\n",
       "0  ------...  \n",
       "2                               contractual oblig...  \n",
       "3           sites  corporate  bd life sciences  b...  \n",
       "4           2006  $ 600883\n",
       "0  ----------  -------...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e38323bf-c65e-4637-acac-154485e53d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================\n",
    "# 4. Sentence Chunking\n",
    "# ====================\n",
    "def split_into_chunks(text, chunk_size=10):\n",
    "    \"\"\"Split text into chunks of `chunk_size` sentences.\"\"\"\n",
    "    doc = nlp(text)\n",
    "    sentences = [str(sent) for sent in doc.sents]\n",
    "    return [sentences[i:i + chunk_size] for i in range(0, len(sentences), chunk_size)]\n",
    "\n",
    "# Process text and tables\n",
    "df[\"sentence_chunks\"] = df[\"text\"].apply(split_into_chunks)\n",
    "df[\"tables_chunks\"] = df[\"tables\"].apply(\n",
    "    lambda x: split_into_chunks(x.to_string()) if isinstance(x, pd.DataFrame) else []\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c43b4cae-a10c-451a-bcb5-345910c64dc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>text</th>\n",
       "      <th>tables</th>\n",
       "      <th>sentence_chunks</th>\n",
       "      <th>tables_chunks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dd4bff516</td>\n",
       "      <td>containerboard , kraft papers and saturating k...</td>\n",
       "      <td>( in millions )  year ended september 30 , ...</td>\n",
       "      <td>[[containerboard , kraft papers and saturating...</td>\n",
       "      <td>[[   ( in millions )  year ended september 30 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dd4c55cc2</td>\n",
       "      <td>entergy mississippi , inc .\\nmanagement's fina...</td>\n",
       "      <td>( in millions )\n",
       "0  ------...</td>\n",
       "      <td>[[entergy mississippi , inc .\\n, management's ...</td>\n",
       "      <td>[[                     ( in millions )\\n0  ---...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dd4c5a718</td>\n",
       "      <td>we have a five year $ 1350 million revolving ,...</td>\n",
       "      <td>contractual oblig...</td>\n",
       "      <td>[[we have a five year $ 1350 million revolving...</td>\n",
       "      <td>[[                                            ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dd4be0184</td>\n",
       "      <td>the agreements that govern the indebtedness in...</td>\n",
       "      <td>sites  corporate  bd life sciences  b...</td>\n",
       "      <td>[[the agreements that govern the indebtedness ...</td>\n",
       "      <td>[[         sites  corporate  bd life sciences ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dd4b93b5e</td>\n",
       "      <td>during 2005 , we amended our $ 1.0 billion uns...</td>\n",
       "      <td>2006  $ 600883\n",
       "0  ----------  -------...</td>\n",
       "      <td>[[during 2005 , we amended our $ 1.0 billion u...</td>\n",
       "      <td>[[         2006  $ 600883\\n0  ----------  ----...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         _id                                               text  \\\n",
       "0  dd4bff516  containerboard , kraft papers and saturating k...   \n",
       "1  dd4c55cc2  entergy mississippi , inc .\\nmanagement's fina...   \n",
       "2  dd4c5a718  we have a five year $ 1350 million revolving ,...   \n",
       "3  dd4be0184  the agreements that govern the indebtedness in...   \n",
       "4  dd4b93b5e  during 2005 , we amended our $ 1.0 billion uns...   \n",
       "\n",
       "                                              tables  \\\n",
       "0     ( in millions )  year ended september 30 , ...   \n",
       "1                       ( in millions )\n",
       "0  ------...   \n",
       "2                               contractual oblig...   \n",
       "3           sites  corporate  bd life sciences  b...   \n",
       "4           2006  $ 600883\n",
       "0  ----------  -------...   \n",
       "\n",
       "                                     sentence_chunks  \\\n",
       "0  [[containerboard , kraft papers and saturating...   \n",
       "1  [[entergy mississippi , inc .\\n, management's ...   \n",
       "2  [[we have a five year $ 1350 million revolving...   \n",
       "3  [[the agreements that govern the indebtedness ...   \n",
       "4  [[during 2005 , we amended our $ 1.0 billion u...   \n",
       "\n",
       "                                       tables_chunks  \n",
       "0  [[   ( in millions )  year ended september 30 ...  \n",
       "1  [[                     ( in millions )\\n0  ---...  \n",
       "2  [[                                            ...  \n",
       "3  [[         sites  corporate  bd life sciences ...  \n",
       "4  [[         2006  $ 600883\\n0  ----------  ----...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c77faef4-ae9f-4244-ad94-45ba4bf71563",
   "metadata": {},
   "outputs": [],
   "source": [
    "def counts(sents):\n",
    "    return len(sents)\n",
    "df[\"sentence_token_counts\"] = df[\"sentence_chunks\"].apply(counts)\n",
    "df[\"table_token_counts\"] = df[\"tables\"].apply(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c480d203-5bca-40b5-a801-6be8045e4f24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>text</th>\n",
       "      <th>tables</th>\n",
       "      <th>sentence_chunks</th>\n",
       "      <th>tables_chunks</th>\n",
       "      <th>sentence_token_counts</th>\n",
       "      <th>table_token_counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dd4bff516</td>\n",
       "      <td>containerboard , kraft papers and saturating k...</td>\n",
       "      <td>( in millions )  year ended september 30 , ...</td>\n",
       "      <td>[[containerboard , kraft papers and saturating...</td>\n",
       "      <td>[[   ( in millions )  year ended september 30 ...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dd4c55cc2</td>\n",
       "      <td>entergy mississippi , inc .\\nmanagement's fina...</td>\n",
       "      <td>( in millions )\n",
       "0  ------...</td>\n",
       "      <td>[[entergy mississippi , inc .\\n, management's ...</td>\n",
       "      <td>[[                     ( in millions )\\n0  ---...</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dd4c5a718</td>\n",
       "      <td>we have a five year $ 1350 million revolving ,...</td>\n",
       "      <td>contractual oblig...</td>\n",
       "      <td>[[we have a five year $ 1350 million revolving...</td>\n",
       "      <td>[[                                            ...</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dd4be0184</td>\n",
       "      <td>the agreements that govern the indebtedness in...</td>\n",
       "      <td>sites  corporate  bd life sciences  b...</td>\n",
       "      <td>[[the agreements that govern the indebtedness ...</td>\n",
       "      <td>[[         sites  corporate  bd life sciences ...</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dd4b93b5e</td>\n",
       "      <td>during 2005 , we amended our $ 1.0 billion uns...</td>\n",
       "      <td>2006  $ 600883\n",
       "0  ----------  -------...</td>\n",
       "      <td>[[during 2005 , we amended our $ 1.0 billion u...</td>\n",
       "      <td>[[         2006  $ 600883\\n0  ----------  ----...</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         _id                                               text  \\\n",
       "0  dd4bff516  containerboard , kraft papers and saturating k...   \n",
       "1  dd4c55cc2  entergy mississippi , inc .\\nmanagement's fina...   \n",
       "2  dd4c5a718  we have a five year $ 1350 million revolving ,...   \n",
       "3  dd4be0184  the agreements that govern the indebtedness in...   \n",
       "4  dd4b93b5e  during 2005 , we amended our $ 1.0 billion uns...   \n",
       "\n",
       "                                              tables  \\\n",
       "0     ( in millions )  year ended september 30 , ...   \n",
       "1                       ( in millions )\n",
       "0  ------...   \n",
       "2                               contractual oblig...   \n",
       "3           sites  corporate  bd life sciences  b...   \n",
       "4           2006  $ 600883\n",
       "0  ----------  -------...   \n",
       "\n",
       "                                     sentence_chunks  \\\n",
       "0  [[containerboard , kraft papers and saturating...   \n",
       "1  [[entergy mississippi , inc .\\n, management's ...   \n",
       "2  [[we have a five year $ 1350 million revolving...   \n",
       "3  [[the agreements that govern the indebtedness ...   \n",
       "4  [[during 2005 , we amended our $ 1.0 billion u...   \n",
       "\n",
       "                                       tables_chunks  sentence_token_counts  \\\n",
       "0  [[   ( in millions )  year ended september 30 ...                      4   \n",
       "1  [[                     ( in millions )\\n0  ---...                      2   \n",
       "2  [[                                            ...                      5   \n",
       "3  [[         sites  corporate  bd life sciences ...                      3   \n",
       "4  [[         2006  $ 600883\\n0  ----------  ----...                      4   \n",
       "\n",
       "   table_token_counts  \n",
       "0                   3  \n",
       "1                   5  \n",
       "2                   9  \n",
       "3                   5  \n",
       "4                   5  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "911a1189-8882-4117-bcf5-baa408bbe6eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample embeddings shape: (768,)\n",
      "Sample embeddings shape: (768,)\n"
     ]
    }
   ],
   "source": [
    "# ====================\n",
    "# 5. Embedding Generation\n",
    "# ====================\n",
    "def generate_chunk_embeddings(chunks):\n",
    "    \"\"\"Generate embeddings for each chunk individually.\"\"\"\n",
    "    if not chunks or len(chunks) == 0:\n",
    "        return []\n",
    "    # Flatten chunks if they're nested lists (some chunks may contain multiple sentences)\n",
    "    flat_chunks = [\" \".join(chunk) if isinstance(chunk, list) else chunk for chunk in chunks]\n",
    "    return embedding_model.encode(flat_chunks, convert_to_numpy=True)\n",
    "\n",
    "# Generate embeddings correctly\n",
    "df[\"text_embeddings\"] = df[\"sentence_chunks\"].apply(\n",
    "    lambda chunks: generate_chunk_embeddings(chunks)\n",
    "\n",
    ")\n",
    "df[\"tables_embeddings\"] = df[\"tables_chunks\"].apply(\n",
    "    lambda tables: generate_chunk_embeddings(tables)\n",
    "\n",
    ")\n",
    "# Verify shapes\n",
    "print(f\"Sample embeddings shape: {df['text_embeddings'].iloc[0][0].shape}\")\n",
    "print(f\"Sample embeddings shape: {df['tables_embeddings'].iloc[0][0].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b974ef5-5468-4a11-bcb6-761661596863",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten chunks and embeddings\n",
    "all_text_chunks = [chunk for doc_chunks in df[\"sentence_chunks\"] for chunk in doc_chunks]\n",
    "all_text_embeddings = [emb for doc_embs in df[\"text_embeddings\"] for emb in doc_embs]\n",
    "all_tables_embeddings = [tab for doc_tab in df[\"tables_embeddings\"] for tab in doc_tab]\n",
    "# # Check consistency\n",
    "# assert len(all_text_chunks) == len(all_text_embeddings), \"Mismatch between chunks and embeddings!\"\n",
    "# print(f\"Total chunks: {len(all_text_chunks)}, Total embeddings: {len(all_text_embeddings)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275cd528-8550-4653-9b0d-988cb716969f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class VectorSearch:\n",
    "#     def __init__(self, embeddings, texts):\n",
    "#         # Stack embeddings into (N, 768) tensor\n",
    "#         self.embeddings = torch.tensor(np.stack(embeddings), dtype=torch.float32).to(device)\n",
    "#         self.texts = texts\n",
    "    \n",
    "#     def search(self, query, top_k=1):\n",
    "#         query_embedding = embedding_model.encode(query, convert_to_tensor=True)\n",
    "#         cos_scores = util.cos_sim(query_embedding, self.embeddings)[0]\n",
    "#         top_indices = torch.topk(cos_scores, k=top_k).indices.cpu().numpy()\n",
    "#         return [(self.texts[i], cos_scores[i].item()) for i in top_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0cc23f1a-7cfe-4eac-ac43-f2a716e89eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================\n",
    "# 6. Vector Search \n",
    "# ====================\n",
    "class VectorSearch:\n",
    "    def __init__(self, embeddings, texts):\n",
    "        # Stack embeddings into (N, 768) tensor\n",
    "        self.embeddings = torch.tensor(np.stack(embeddings), dtype=torch.float32).to(device)\n",
    "        self.texts = texts\n",
    "    \n",
    "    def search(self, query, top_k=1):\n",
    "        \n",
    "        \"\"\"Search for top_k most similar chunks (now defaults to top 1)\"\"\"\n",
    "        query_embedding = embedding_model.encode(query, convert_to_tensor=True)\n",
    "        cos_scores = util.cos_sim(query_embedding, self.embeddings)[0]\n",
    "        top_indices = torch.topk(cos_scores, k=top_k).indices.cpu().numpy()\n",
    "        return [(self.texts[i], cos_scores[i].item()) for i in top_indices] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b20eea57-caa8-4fb6-9b60-8a6d45ee4462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for 'what was the increase in the operating profit for space systems from 2011 to 2012?':\n",
      "\n",
      "Rank 1 (Score: 0.7500):\n",
      "| 13.0% ( 13.0 % )\n",
      "backlog at year-end | $ 18900          | $ 20500          | $ 18100         \n",
      "\n",
      "2014 compared to 2013 space systems 2019 net sales for 2014 increased $ 107 million , or 1% ( 1 % ) , compared to 2013 .\n",
      " the increase was primarily attributable to higher net sales of approximately $ 340 million for the orion program due to increased volume ( primarily the first unmanned test flight of the orion mpcv ) ; and about $ 145 million for commercial space transportation programs due to launch-related activities .\n",
      " the increases were offset by lower net sales of approximately $ 335 million for government satellite programs due to decreased volume ( primarily aehf , gps-iii and muos ) ; and about $ 45 million for various other programs due to decreased volume .\n",
      "space systems 2019 operating profit for 2014 was comparable to 2013 .\n",
      " operating profit decreased by approximately $ 20 million for government satellite programs due to lower volume ( primarily aehf and gps-iii ) , partially offset by increased risk retirements ( primarily muos ) ; and about $ 20 million due to decreased equity earnings for joint ventures .\n",
      " the decreases were offset by higher operating profit of approximately $ 30 million for the orion program due to increased volume .\n",
      "operating profit was reduced by approximately $ 40 million for charges , net of recoveries , related to the restructuring action announced in november 2013 .\n",
      " adjustments not related to volume , including net profit booking rate adjustments and other matters , were approximately $ 10 million lower for 2014 compared to 2013 .\n",
      " 2013 compared to 2012 space systems 2019 net sales for 2013 decreased $ 389 million , or 5% ( 5 % ) , compared to 2012 .\n",
      " the decrease was primarily attributable to lower net sales of approximately $ 305 million for commercial satellite programs due to fewer deliveries ( zero delivered during 2013 compared to two for 2012 ) ; and about $ 290 million for the orion program due to lower volume .\n",
      " the decreases were partially offset by higher net sales of approximately $ 130 million for government satellite programs due to net increased volume ; and about $ 65 million for strategic and defensive missile programs ( primarily fbm ) due to increased volume and risk retirements .\n",
      " the increase for government satellite programs was primarily attributable to higher volume on aehf and other programs , partially offset by lower volume on goes-r , muos and sbirs programs .\n",
      "space systems 2019 operating profit for 2013 decreased $ 38 million , or 4% ( 4 % ) , compared to 2012 .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize search\n",
    "text_searcher = VectorSearch(all_text_embeddings, all_text_chunks)\n",
    "\n",
    "# Test query\n",
    "query = \"what was the increase in the operating profit for space systems from 2011 to 2012?\"\n",
    "results = text_searcher.search(query)\n",
    "\n",
    "print(f\"Results for '{query}':\")\n",
    "for i, (chunk, score) in enumerate(results):\n",
    "    print(f\"\\nRank {i+1} (Score: {score:.4f}):\")\n",
    "    print(chunk if isinstance(chunk, str) else \" \".join(chunk))  # Handle both str and list chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4cbac919-3253-4217-9c05-7fd7a7c53c94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top results for 'What was the net sales in 2019?':\n",
      "\n",
      "Rank 1 (Score: 0.6978):\n",
      "['| --------------\\nnet sales           | $ 7153           | $ 7579         | $ 7132        \\noperating profit    | 905              | 737            | 645           \\noperating margins   | 12.7% ( 12.7 % )', '| 9.7% ( 9.7 % )', '| 9.0% ( 9.0 % )\\nbacklog at year-end | 10800            | 10700          | 10500         \\n\\n2013 compared to 2012 mst 2019s net sales for 2013 decreased $ 426 million , or 6% ( 6 % ) , compared to 2012 .\\n', 'the decrease was primarily attributable to lower net sales of approximately $ 275 million for various ship and aviation systems programs due to lower volume']\n"
     ]
    }
   ],
   "source": [
    "# ====================\n",
    "# 7. Example Query\n",
    "# ====================\n",
    "query = \"What was the net sales in 2019?\"\n",
    "results = text_searcher.search(query)\n",
    "\n",
    "print(f\"Top results for '{query}':\")\n",
    "for i, (chunk, score) in enumerate(results):\n",
    "    print(f\"\\nRank {i + 1} (Score: {score:.4f}):\")\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f9c44b-4fee-442b-8348-b11176ff2920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================\n",
    "# 8. Save/Load System\n",
    "# ====================\n",
    "# Save embeddings and metadata\n",
    "pd.DataFrame({\n",
    "    \"text\": all_text_chunks,\n",
    "    \"embedding\": [emb.tolist() for emb in all_text_embeddings]\n",
    "}).to_parquet(\"financial_embeddings.parquet\")\n",
    "\n",
    "# Load for later use\n",
    "# loaded_df = pd.read_parquet(\"financial_embeddings.parquet\")\n",
    "# loaded_embeddings = torch.tensor(np.stack(loaded_df[\"embedding\"].values)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d8da9ad9-4286-403e-a33f-a0d3cab26b1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available GPU memory: 12 GB\n",
      "GPU memory: 12 | Recommended model: Gemma 2B in float16 or Gemma 7B in 4-bit precision.\n",
      "use_quantization_config set to: False\n",
      "model_id set to: google/gemma-2b-it\n"
     ]
    }
   ],
   "source": [
    "#=====================\n",
    "#10. llm loading\n",
    "#=====================\n",
    "gpu_memory_bytes = torch.cuda.get_device_properties(0).total_memory\n",
    "gpu_memory_gb = round(gpu_memory_bytes / (2**30))\n",
    "print(f\"Available GPU memory: {gpu_memory_gb} GB\")\n",
    "if gpu_memory_gb < 5.1:\n",
    "    print(f\"Your available GPU memory is {gpu_memory_gb}GB, you may not have enough memory to run a Gemma LLM locally without quantization.\")\n",
    "elif gpu_memory_gb < 8.1:\n",
    "    print(f\"GPU memory: {gpu_memory_gb} | Recommended model: Gemma 2B in 4-bit precision.\")\n",
    "    use_quantization_config = True \n",
    "    model_id = \"google/gemma-2b-it\"\n",
    "elif gpu_memory_gb < 19.0:\n",
    "    print(f\"GPU memory: {gpu_memory_gb} | Recommended model: Gemma 2B in float16 or Gemma 7B in 4-bit precision.\")\n",
    "    use_quantization_config = False \n",
    "    model_id = \"google/gemma-2b-it\"\n",
    "elif gpu_memory_gb > 19.0:\n",
    "    print(f\"GPU memory: {gpu_memory_gb} | Recommend model: Gemma 7B in 4-bit or float16 precision.\")\n",
    "    use_quantization_config = False \n",
    "    model_id = \"google/gemma-7b-it\"\n",
    "\n",
    "print(f\"use_quantization_config set to: {use_quantization_config}\")\n",
    "print(f\"model_id set to: {model_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "22932b04-1172-4837-a0a6-765d8033ce45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=====================\n",
    "#10. llm setup\n",
    "#=====================\n",
    "# setup/libraries\n",
    "from transformers import BitsAndBytesConfig\n",
    "from transformers.utils import is_flash_attn_2_available\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from transformers import BartForConditionalGeneration, BartTokenizer\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "quantization_config = BitsAndBytesConfig(load_in_4bit=True,\n",
    "                                         bnb_4bit_compute_dtype=torch.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e64edab7-65f5-453e-8807-c38b0e944d40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using attention implementation: flash_attention_2\n",
      "[INFO] Using model_id: google/gemma-2b-it\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shegun93/anaconda3/envs/TTS/lib/python3.9/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.\n",
      "Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [03:00<00:00, 90.30s/it]\n"
     ]
    }
   ],
   "source": [
    "#=====================\n",
    "#11. llm loading\n",
    "#=====================\n",
    "if (is_flash_attn_2_available()) and (torch.cuda.get_device_capability(0)[0] >= 8):\n",
    "  attn_implementation = \"flash_attention_2\"\n",
    "else:\n",
    "  attn_implementation = \"sdpa\"\n",
    "print(f\"[INFO] Using attention implementation: {attn_implementation}\")\n",
    "print(f\"[INFO] Using model_id: {model_id}\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name_or_path=model_id)\n",
    "Gamma_model = AutoModelForCausalLM.from_pretrained(pretrained_model_name_or_path=model_id, \n",
    "                                                 torch_dtype=torch.float16,\n",
    "                                                 quantization_config=quantization_config if use_quantization_config else None,\n",
    "                                                 low_cpu_mem_usage=False,\n",
    "                                                 attn_implementation=attn_implementation) \n",
    "if not use_quantization_config:\n",
    "    Gamma_model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "23085aeb-5ede-44ad-9364-040b7ddd72c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================\n",
    "# 11. Unified RAG Query Function\n",
    "# ====================\n",
    "def ask(query, \n",
    "        temperature=1,\n",
    "        max_new_tokens=512,\n",
    "        format_answer_text=True, \n",
    "        return_answer_only=True,\n",
    "        task=\"qa\"):\n",
    "    \n",
    "    # --- RETRIEVAL ---\n",
    "# In ask() function, change:\n",
    "    top_chunk, score = text_searcher.search(query, top_k=1)[0]  # Get first result    \n",
    "    # --- PROMPT FORMATTING ---\n",
    "    prompt = f\"\"\"Answer the question based on the context below. Be concise.\n",
    "    \n",
    "    Question: {query}\n",
    "    Context: {top_chunk if isinstance(top_chunk, str) else ' '.join(top_chunk)}\n",
    "    Answer:\"\"\"\n",
    "    \n",
    "    # --- GENERATION ---\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(Gamma_model.device)\n",
    "    outputs = Gamma_model.generate(\n",
    "        **inputs,\n",
    "        temperature=temperature,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        do_sample=True,\n",
    "        pad_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "    \n",
    "    # --- RESPONSE CLEANING ---\n",
    "    full_response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    answer = full_response.replace(prompt, \"\").strip() if format_answer_text else full_response\n",
    "    \n",
    "    # --- RETURN ---\n",
    "    return answer if return_answer_only else (answer, top_chunk, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0dc9e315-0bb6-4044-86a1-87030e1c2735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================\n",
    "# Testing Function \n",
    "# ====================\n",
    "def test_rag_system(query: str, \n",
    "                   show_context: bool = True,\n",
    "                   max_new_tokens: int = 256) -> str:\n",
    "\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"QUERY: {query}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    answer, context_chunk, score = ask(\n",
    "        query=query,\n",
    "        return_answer_only=False,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        task=\"qa\"\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nANSWER:\\n{answer}\\n\")\n",
    "    \n",
    "    if show_context:\n",
    "        print(f\"{'-'*50}\")\n",
    "        print(f\"CONTEXT (Score: {score:.4f}):\")\n",
    "        #print(textwrap.fill(str(context_chunk)[:500], width=80))\n",
    "        print(f\"{'-'*50}\")\n",
    "        # Add this to your test_rag_system() before generation:\n",
    "    \n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3dff0d6e-7c18-47f8-867f-f82329d368e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "QUERY: what is the net change in estimated future net amortization expense of present value of future profits from 2013 to 2014?\n",
      "==================================================\n",
      "\n",
      "ANSWER:\n",
      "$ 24\n",
      "\n",
      "Therefore, the net change in estimated future net amortization expense of present value of future profits from 2013 to 2014 is $ 24.\n",
      "\n",
      "--------------------------------------------------\n",
      "CONTEXT (Score: 0.6848):\n",
      "--------------------------------------------------\n",
      "\n",
      "====================================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize searcher (do this once)\n",
    "text_searcher = VectorSearch(all_text_embeddings, all_text_chunks)\n",
    "\n",
    "# Test queries\n",
    "test_queries = [\n",
    "    \"what is the net change in estimated future net amortization expense of present value of future profits from 2013 to 2014?\",\n",
    "]\n",
    "\n",
    "for query in test_queries:\n",
    "    test_rag_system(query)\n",
    "    print(\"\\n\" + \"=\"*100 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4588271-3e92-41fe-8c1a-b12b4671da33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
